# Light Agent Configuration Example

# --- Workspace ---
WORKSPACE_DIR="./workspace"

# --- LLM Providers ---
# Choices: ollama/model_name, gemini/model_name, openai/model_name
DEFAULT_MODEL="ollama/llama3"
FAST_MODEL="ollama/phi3"      # Faster, smaller model for summaries
REASONING_MODEL="ollama/llama3:70b" # Powerful model for reasoning

# Ollama
OLLAMA_BASE_URL="http://localhost:11434"

# Google Gemini
GOOGLE_API_KEY="your-gemini-api-key"

# LLMStudy Specific (if applicable)
LLMSTUDY_API_KEY="your-llmstudy-api-key"
LLMSTUDY_BASE_URL="https://api.llmstudy.com/v1"
ENABLE_STREAMING=False

# Enabled Tools/Skills
ENABLED_TOOLS="shell_command,fetch_content,get_system_load"
AUTO_APPROVE_SHELL=false

# MCP Servers (External)
# Managed via workspace/servers_config.json

# --- Logging ---
LOG_LEVEL="INFO"
