# Light Agent

Lightweight SRE AI Agent designed for local execution and portability.

## Documentation

- [Architecture Overview](docs/architecture.md)
- [Workspace Structure](docs/workspace.md)
- [Providers Configuration](docs/providers.md)
- [Tools & MCP Integrations](docs/tools_mcp.md)


## Usage

Start a chat with the agent:
```bash
uv run lightagent chat
```

Or run a single prompt:
```bash
uv run lightagent chat "Sua pergunta aqui"
```

Use verbose mode for detailed logs:
```bash
uv run lightagent chat "Sua pergunta aqui" --verbose
```

### Slash Commands
Inside the interactive chat mode, you can use the following commands:
- `/new`: Clear current conversation history and start fresh.
- `/status`: Show connected MCP servers and loaded markdown skills.
- `/reset`: Restart tools and reconnect to MCP servers.
- `/quit` or `/exit`: Close the session.

## Core Features

### 1. LLM Providers
Supported via `litellm`:
- **Ollama**: Local execution (llama3, mistral).
- **Google Gemini**: Remote high-reasoning tasks.
- **LLMStudy**: Custom OpenAI-compatible endpoints.

### 2. Tools & Skills
- **Native Tools**: `exec`, `list_dir`, `read_file`, `write_file`, `web_search`, `web_fetch`.
- **Markdown Skills**: Discovered in `light_agent/base/skills/` (fallback to `workspace/skills/`).
- **Sub-agents**: Task delegation via `spawn`, `parallel_spawn`, and result coordination via `wait_subagents`.

### 3. MCP Integrations
Connect to external Model Context Protocol servers (e.g., Google Drive, Slack) by configuring `light_agent/base/servers_config.json` (or `workspace/servers_config.json`).

### 4. Structured Memory
- **Long-term Memory (SQLite)**: Stores full interaction history in `data/memory/long_memory.db`. Uses BM25 for semantic search.
- **Fixed Facts (MEMORY.md)**: Stores immutable user facts (e.g., preferences, tech stack) in `light_agent/base/memory/MEMORY.md` (or `workspace/memory/MEMORY.md`).
- **Auto-Summary**: Portuguese summaries generated by the LLM for every Q&A.

## Roadmap & Future Issues

| Feature | Category | Status | Description |
| :--- | :--- | :--- | :--- |
| **Long-term Memory** | Memory | ✅ Done | Persistent storage using SQLite + BM25 with time-based filtering (e.g., last 30d). |
| **Parallel Subagents** | Agents | ✅ Done | Enable multiple subagents to work concurrently on complex tasks. |
| **Multi-Model Orchestration** | LLM | ✅ Done | Use different models for reasoning (main loop) vs. speed (summaries). |
| **Interactive Chat Mode** | CLI | ✅ Done | Persistent chat session launched via `uv run lightagent chat`. |
| **Slash Commands** | CLI | ✅ Done | Support for commands like `/new`, `/reset`, and `/status` within the chat. |
| **Security Hardening** | Security | ✅ Done | Shell command allowlist, SSRF protection, workspace restriction. |

## Security Features

Light Agent includes enterprise-grade security controls:

### Shell Command Safety
- **Command Allowlist**: Only 60+ pre-approved commands can be executed
- **Shell Injection Protection**: Blocks metacharacters (`;|&$<>`{}[]\\*?)
- **Destructive Pattern Blocking**: Prevents `rm -rf`, fork bombs, disk writes
- **Subprocess Isolation**: Uses `create_subprocess_exec()` instead of shell=True

### SSRF Protection (Web Tools)
- **Private IP Blocking**: RFC 1918 addresses (10.x, 172.16.x, 192.168.x)
- **Cloud Metadata Protection**: Blocks AWS/GCP/Azure metadata endpoints

### Workspace Security
- **RESTRICT_TO_WORKSPACE**: All file operations confined to workspace (default: enabled)

Configure in `.env`:
```env
RESTRICT_TO_WORKSPACE=true  # Default: true
```

